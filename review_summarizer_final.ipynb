{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "review_summarizer_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jMmFmFwktn6s",
        "bqPWZDeNtp8g",
        "ik88DDj7t6Lr"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a7a66050bed4f609e84c28e5568c905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a3b899aa8ee4f4f87005d5ec4d2306c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f68ea15445e4d84842336bc9bdc01d0",
              "IPY_MODEL_5de97783bb2a41a8b22c90bf73fea799"
            ]
          }
        },
        "2a3b899aa8ee4f4f87005d5ec4d2306c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f68ea15445e4d84842336bc9bdc01d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c4a6574f1b7f445d9433783221573079",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f1ee68cf47b40caa4797f165ad6f4af"
          }
        },
        "5de97783bb2a41a8b22c90bf73fea799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_72baa954c6704765b23f99bf997b1873",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [3:23:41&lt;00:00, 122.21s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd00b3b9d3b945dd974978137b0f982f"
          }
        },
        "c4a6574f1b7f445d9433783221573079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f1ee68cf47b40caa4797f165ad6f4af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72baa954c6704765b23f99bf997b1873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd00b3b9d3b945dd974978137b0f982f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMmFmFwktn6s",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrBmGKsUALUQ",
        "colab_type": "code",
        "outputId": "411ae391-e24f-4e5d-c1aa-209103f4eaff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Apr 14 13:16:16 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    32W / 250W |   2407MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec1S6B5_RTVQ",
        "colab_type": "code",
        "outputId": "24901623-5814-4dd2-9572-877560344754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.38)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1pvOUngDv3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install rouge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ImaqF5A1gWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import gzip\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import time\n",
        "import spacy\n",
        "import torch\n",
        "import sys\n",
        "import random \n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adagrad\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer\n",
        "from torch.utils.data import RandomSampler, DataLoader, TensorDataset, random_split\n",
        "import copy\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.nn.utils.rnn import pad_sequence       \n",
        "from rouge import FilesRouge\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj0h1KtjdVdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set device for switching between CPU and GPU.\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q28_bxXSvk3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6e5fcf0-64e2-4be5-e686-030789b67001"
      },
      "source": [
        "# Mount google drive to access files.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqPWZDeNtp8g",
        "colab_type": "text"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrDX-jdq1jcJ",
        "colab_type": "code",
        "outputId": "eab4b109-9f06-4d3a-86de-c4acef116c6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Import dataset from online.\n",
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Software_5.json.gz"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-14 13:16:32--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Software_5.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5339013 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘Software_5.json.gz.1’\n",
            "\n",
            "Software_5.json.gz. 100%[===================>]   5.09M  8.34MB/s    in 0.6s    \n",
            "\n",
            "2020-04-14 13:16:33 (8.34 MB/s) - ‘Software_5.json.gz.1’ saved [5339013/5339013]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gBkywVn1lcJ",
        "colab_type": "code",
        "outputId": "e2455c0a-dd02-4aaa-e9de-e55164b52df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "dataset = []\n",
        "with gzip.open('Software_5.json.gz') as f:\n",
        "    for l in f:\n",
        "        dataset.append(json.loads(l.strip()))\n",
        "    \n",
        "# total length of list, this number equals total number of products\n",
        "print(len(dataset))\n",
        "\n",
        "# first row of the list\n",
        "print(dataset[0])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12805\n",
            "{'overall': 4.0, 'verified': False, 'reviewTime': '10 20, 2010', 'reviewerID': 'A38NELQT98S4H8', 'asin': '0321719816', 'style': {'Format:': ' DVD-ROM'}, 'reviewerName': 'WB Halper', 'reviewText': \"I've been using Dreamweaver (and it's predecessor Macromedia's UltraDev) for many years.  For someone who is an experienced web designer, this course is a high-level review of the CS5 version of Dreamweaver, but it doesn't go into a great enough level of detail to find it very useful.\\n\\nOn the other hand, this is a great tool for someone who is a relative novice at web design.  It starts off with a basic overview of HTML and continues through the concepts necessary to build a modern web site.  Someone who goes through this course should exit with enough knowledge to create something that does what you want it do do...within reason.  Don't expect to go off and build an entire e-commerce system with only this class under your belt.\\n\\nIt's important to note that there's a long gap from site design to actual implementation.  This course teaches you how to implement a design.  The user interface and overall user experience is a different subject that isn't covered here...it's possible to do a great implementation of an absolutely abysmal design.  I speak from experience.  :)\\n\\nAs I said above, if you're a novice, a relative newcomer or just an experienced web designer who wants a refresher course, this is a good way to do it.\", 'summary': 'A solid overview of Dreamweaver CS5', 'unixReviewTime': 1287532800}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3gqPWHW1nY7",
        "colab_type": "code",
        "outputId": "bfd8aeb1-6409-4e29-b848-8707bab9d643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert dictionary into pandas dataframe.\n",
        "data = pd.DataFrame.from_dict(dataset)\n",
        "\n",
        "print(len(data))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCa1UnWJ48Md",
        "colab_type": "code",
        "outputId": "4b9a7ae1-9c36-4f4c-9c33-8b35fecb51f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Check for null values.\n",
        "data.isnull().sum()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "overall               0\n",
              "verified              0\n",
              "reviewTime            0\n",
              "reviewerID            0\n",
              "asin                  0\n",
              "style              5644\n",
              "reviewerName          9\n",
              "reviewText            1\n",
              "summary               6\n",
              "unixReviewTime        0\n",
              "vote               8903\n",
              "image             12734\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTdj9Xur5CK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove null values and unneeded features.\n",
        "data = data.drop(['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'style',\n",
        "       'reviewerName', 'unixReviewTime', 'vote',\n",
        "       'image'], 1)\n",
        "data = data.reset_index(drop=True)\n",
        "data = data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TLlg4k-djsj8",
        "colab": {}
      },
      "source": [
        "# Create columns of for review and summary lengths.\n",
        "data['review_length'] = data.reviewText.apply(lambda x: len(x.split()))\n",
        "data['summary_length'] = data.summary.apply(lambda x: len(x.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "85607765-6388-49f2-c52c-adf39d25e18b",
        "id": "-pktnvfsjsj_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "source": [
        "# Plot distribution of review lengths.\n",
        "print(data.review_length.describe(percentiles = [0.25, 0.9, 0.95, 0.99]))\n",
        "axarr = data.review_length.hist(bins = 100,figsize = (20,10))\n",
        "axarr.set_xlabel(\"Review Length\")\n",
        "axarr.set_ylabel(\"Count\")\n",
        "axarr.set_xlim(0, 1000)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    8070.000000\n",
            "mean      229.638042\n",
            "std       289.433605\n",
            "min         1.000000\n",
            "25%        68.000000\n",
            "50%       147.000000\n",
            "90%       499.100000\n",
            "95%       716.100000\n",
            "99%      1362.930000\n",
            "max      5118.000000\n",
            "Name: review_length, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1000.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JXlL-T0ajskB",
        "outputId": "180a5d78-8fb5-43f2-e3ec-d8b435fd2576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "# Plot distribution of summary lengths.\n",
        "print(data.summary_length.describe(percentiles = [0.9,0.95,0.99]))\n",
        "axarr1 = data.summary_length.hist(bins = 100,figsize = (20,10))\n",
        "axarr1.set_xlabel(\"Summary Length\")\n",
        "axarr1.set_ylabel(\"Count\")"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    8070.000000\n",
            "mean        7.641884\n",
            "std         3.526348\n",
            "min         4.000000\n",
            "50%         7.000000\n",
            "90%        12.000000\n",
            "95%        15.000000\n",
            "99%        20.000000\n",
            "max        27.000000\n",
            "Name: summary_length, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaV1uyPvZ9pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Revome review summary pairs with summaries less than three words.\n",
        "data = data[(data['summary_length'] > 3)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-su8PtB_bCbp",
        "colab_type": "code",
        "outputId": "64f0ce27-e85c-49be-b9b6-68d83a925cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Final dataset size\n",
        "len(data)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8070"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8fDuIaqVZQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split into training and validation set.\n",
        "train_set = data.sample(frac=0.80, random_state=1537) \n",
        "test_set = data.drop(train_set.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isEnUj3AVtXc",
        "colab_type": "code",
        "outputId": "72cdbab1-e194-45ab-8b8e-9811d6331cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(train_set))\n",
        "print(len(test_set))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6456\n",
            "1614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz46d2fUZdF5",
        "colab_type": "code",
        "outputId": "d40e953a-b919-42e9-8a0a-de66fe3e6116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_set[:5]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>review_length</th>\n",
              "      <th>summary_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5231</th>\n",
              "      <td>I have been through a large number of PC secur...</td>\n",
              "      <td>Good product, but too much?</td>\n",
              "      <td>248</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7057</th>\n",
              "      <td>Preliminary Review - - -\\n\\nI have used TurboT...</td>\n",
              "      <td>CAUTION !!!  SCAM ALERT !!!</td>\n",
              "      <td>532</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>There is no perfect AV software.  Most aren't ...</td>\n",
              "      <td>Kaspersky continues to do the job right</td>\n",
              "      <td>88</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6311</th>\n",
              "      <td>Norton Internet Security for MAC - a great pro...</td>\n",
              "      <td>Just ok - great product IF it was needed, whic...</td>\n",
              "      <td>47</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1307</th>\n",
              "      <td>I switched to mac after Vista problems. I love...</td>\n",
              "      <td>Switched to the mac, LOVE LOVE LOVE it!</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviewText  ... summary_length\n",
              "5231  I have been through a large number of PC secur...  ...              5\n",
              "7057  Preliminary Review - - -\\n\\nI have used TurboT...  ...              5\n",
              "7609  There is no perfect AV software.  Most aren't ...  ...              7\n",
              "6311  Norton Internet Security for MAC - a great pro...  ...             12\n",
              "1307  I switched to mac after Vista problems. I love...  ...              8\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik88DDj7t6Lr",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess and Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNvn5QxO6DIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings.\n",
        "def clean_text(text):\n",
        "    # Format words and remove unwanted characters\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text) \n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "    text = re.sub('([.,!?()])', r' \\1 ', text)\n",
        "    text = re.sub('\\s{2,}', ' ', text)  \n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM93EPZBWDTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean all reviews and summaries.\n",
        "def clean_data(dataset, text_type):\n",
        "  clean_texts = []\n",
        "  for x in dataset[text_type]:\n",
        "    clean_texts.append(clean_text(x).lower())\n",
        "  return clean_texts\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MySd-xS59SGQ",
        "colab_type": "code",
        "outputId": "02aeb736-93ed-4851-eb93-60b849f4ae47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Clean the summaries and texts\n",
        "clean_summaries_train = clean_data(train_set, \"summary\")\n",
        "print(\"Train summaries are complete.\")\n",
        "\n",
        "clean_summaries_test = clean_data(test_set, \"summary\")\n",
        "print(\"Test summaries are complete.\")\n",
        "\n",
        "clean_reviews_train = clean_data(train_set, \"reviewText\")\n",
        "print(\"Train reviews are complete.\")\n",
        "\n",
        "clean_reviews_test = clean_data(test_set, \"reviewText\")\n",
        "print(\"Test reviews are complete.\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train summaries are complete.\n",
            "Test summaries are complete.\n",
            "Train reviews are complete.\n",
            "Test reviews are complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI6JppfboqTd",
        "colab_type": "code",
        "outputId": "48f355d4-b336-43c9-ff86-42a396611243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Subset out any reviews and summaries that are longer than 512 tokens.\n",
        "# Due to using BERT encoder.\n",
        "subset_reviews_train = []\n",
        "subset_summaries_train = []\n",
        "for rev, summary in zip(clean_reviews_train, clean_summaries_train):\n",
        "  if len(rev.split()) < 512:\n",
        "    subset_reviews_train.append(rev)\n",
        "    subset_summaries_train.append(summary)\n",
        "\n",
        "\n",
        "subset_reviews_test = []\n",
        "subset_summaries_test = []\n",
        "for rev, summary in zip(clean_reviews_test, clean_summaries_test):\n",
        "  if len(rev.split()) < 512:\n",
        "    subset_reviews_test.append(rev)\n",
        "    subset_summaries_test.append(summary)\n",
        "\n",
        "print(len(subset_reviews_train))\n",
        "print(len(subset_summaries_train))\n",
        "print(len(subset_reviews_test))\n",
        "print(len(subset_summaries_test))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5643\n",
            "5643\n",
            "1430\n",
            "1430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAiPBTOSnhhR",
        "colab_type": "code",
        "outputId": "80205b09-2491-4ee9-fa34-23c9eaf91c71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Map words to index. Create vocabulary for decoder.\n",
        "word_to_ix = {'[PAD]':0, '<sos>':1, '<eos>':2, '[UNK]':3}\n",
        "\n",
        "for sent in subset_reviews_train:\n",
        "    for word in sent.split():\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "for sent in subset_summaries_train:\n",
        "    for word in sent.split():\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "for sent in subset_reviews_test:\n",
        "    for word in sent.split():\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "for sent in subset_summaries_test:\n",
        "    for word in sent.split():\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "ix_to_word = {v:k for k, v in word_to_ix.items()}\n",
        "\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "\n",
        "print(f\"Vocabulary size is {len(word_to_ix)}\")\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size is 19360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wslTCEiMVn3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize and encode reviews and vocabulary. Able to handle out of vocab\n",
        "# words by creating a tempory index and encoding with that value. \n",
        "def article2ids(article_words):\n",
        "  ids = []\n",
        "  oovs = []\n",
        "  unk_id = word_to_ix['[UNK]']\n",
        "  vocab_size = len(word_to_ix.keys())\n",
        "  for w in article_words:\n",
        "    i = word2id(w)\n",
        "    if i == unk_id: \n",
        "      if w not in oovs: \n",
        "        oovs.append(w)\n",
        "      oov_num = oovs.index(w) \n",
        "      ids.append(vocab_size + oov_num) \n",
        "    else:\n",
        "      ids.append(i)\n",
        "  return ids, oovs\n",
        "\n",
        "# Checks if word is in dictionary.\n",
        "def word2id(word):\n",
        "  if word not in word_to_ix:\n",
        "    return word_to_ix['[UNK]']\n",
        "  return word_to_ix[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfvLqckXxWdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates the boolean tags to take the first word piece.\n",
        "def create_tags(tokenizer, review):\n",
        "  reference_tags = []\n",
        "  cur_bool = True\n",
        "  words = review.split()\n",
        "  for word in words:\n",
        "    idxs = tokenizer.tokenize(word)\n",
        "    for i in range(len(idxs)):\n",
        "      if i == 0:\n",
        "        reference_tags.append(cur_bool)\n",
        "      else:\n",
        "        cur_bool = False\n",
        "        reference_tags.append(cur_bool)\n",
        "      cur_bool = True\n",
        "  return reference_tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swa9MYBC0D_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess all reviews and summaries to be used in the model.\n",
        "# Returns a BERT encoded source document, a boolean mask to get the \n",
        "# first word pieces, an encoding of the summaries with our own vocabulary\n",
        "# , all OOV words, and an OOV encoding of the targets.\n",
        "def preprocess(tokenizer, review, summary, oov_summary):\n",
        "  review = \" \".join(review.split(' '))\n",
        "  src_subtoken_idxs = torch.tensor(tokenizer.encode(review, add_special_tokens=False)).unsqueeze(0)\n",
        "  reference_tags = create_tags(tokenizer, review)\n",
        "\n",
        "  if src_subtoken_idxs.shape[1] > 512:\n",
        "      src_subtoken_idxs = src_subtoken_idxs.narrow(1, 0, 512)\n",
        "      reference_tags = reference_tags[:512]\n",
        "\n",
        "\n",
        "  tgt_idxs = [word_to_ix[w] if w in word_to_ix else word_to_ix['[UNK]'] for w in summary.split()]\n",
        "  tgt_subtoken_idxs = torch.tensor(tgt_idxs, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "\n",
        "\n",
        "  review_oov_idxs, review_oovs = article2ids(review.split()[:reference_tags.count(True)])\n",
        "  summary_oov_idxs, summary_oovs = article2ids(oov_summary.split())\n",
        "  tgt_oov_subtoken_idxs = torch.tensor(summary_oov_idxs, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "  if reference_tags.count(True) != len(review_oov_idxs):\n",
        "    print(reference_tags.count(True), len(review_oov_idxs))\n",
        "\n",
        "\n",
        "  return src_subtoken_idxs, tgt_subtoken_idxs, review_oov_idxs, review_oovs, tgt_oov_subtoken_idxs, reference_tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E497XpRlfppN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates the dataset. Which is a list containing dictionaries\n",
        "# that hold the items from the preprocess method.\n",
        "def create_token_dataset(reviews, summaries):\n",
        "  token_dataset = []\n",
        "  tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "  for review, summary in zip(reviews, summaries):\n",
        "    orig_summary = \"<sos> \" + summary \n",
        "    oov_summary = summary + \" <eos>\"\n",
        "    \n",
        "    src_subtoken_idxs, tgt_subtoken_idxs, review_oov_idxs, review_oovs, summary_oov_idxs, reference_tags = preprocess(tokenizer, review, orig_summary, oov_summary)\n",
        "\n",
        "    if src_subtoken_idxs.shape[1] > 512:\n",
        "      src_subtoken_idxs = src_subtoken_idxs.narrow(1, 0, 512)\n",
        "      reference_tags = reference_tags[:512]\n",
        "\n",
        "    if tgt_subtoken_idxs.shape[1] > 512:\n",
        "      tgt_subtoken_idxs = tgt_subtoken_idxs.narrow(1, 0, 512)\n",
        "\n",
        "    if src_subtoken_idxs.shape[1] > 512:\n",
        "      print(\"max len: \", src_subtoken_idxs.shape[1])\n",
        "\n",
        "    if len(review_oov_idxs) > 512:\n",
        "      print(\"review len: \", len(review_oov_idxs))\n",
        "\n",
        "    review_data_dict = {\"src\": src_subtoken_idxs, \"tgt\":tgt_subtoken_idxs,\n",
        "                        \"src_oov_idx\": review_oov_idxs, \"srv_oovs\": review_oovs,\n",
        "                        \"tgt_oov_idx\": summary_oov_idxs, \"ref_tags\": reference_tags}\n",
        "    token_dataset.append(review_data_dict)\n",
        "\n",
        "  return token_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLE04jicgZfP",
        "colab_type": "code",
        "outputId": "f1002c01-4374-41bc-fbf1-f5e83a095d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Tokenize and encode the dataset.\n",
        "tokenized_reviews_train = create_token_dataset(subset_reviews_train, subset_summaries_train)\n",
        "tokenized_reviews_test = create_token_dataset(subset_reviews_test, subset_summaries_test)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (553 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS-DCjW6Tu1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split validation set into validation and test set.\n",
        "tokenized_reviews_validation = tokenized_reviews_test[:800]\n",
        "tokenized_reviews_test = tokenized_reviews_test[800:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxdmWHyduTz1",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qagk4h4FOF-P",
        "colab_type": "text"
      },
      "source": [
        "Code from this section was influenced from a pytorch implementation of the PointerGen Model at this Github Page https://github.com/atulkum/pointer_summarizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0FfFwjquMXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder class which is made up of a DistillBERT transformer. \n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, hidden_dim, decoder_hidden_dim):\n",
        "    super(Encoder, self).__init__()\n",
        "    hidden_dim = hidden_dim\n",
        "    embed_dim = embed_dim\n",
        "    dec_hidden_dim = decoder_hidden_dim\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed_dim = embed_dim\n",
        "    self.dec_hidden_dim = dec_hidden_dim\n",
        "\n",
        "\n",
        "    self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased', output_hidden_states=True)\n",
        "    \n",
        "    for param in self.bert.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    self.bert.vocab_size = vocab_size\n",
        "    self.map_2_decoder = nn.Linear(self.hidden_dim,  self.dec_hidden_dim).to(device)\n",
        "\n",
        "    for param in self.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "  def forward(self, src, attn_mask, prep_tags):\n",
        "    encoder_outputs = self.bert(src, attn_mask)\n",
        "    output = encoder_outputs[0]\n",
        "    output = output.contiguous()\n",
        "    token_embeddings = [output[b][m] for b, m in enumerate(prep_tags)]\n",
        "    output = pad_sequence(token_embeddings, batch_first=True)\n",
        "    output_feature = output.view(-1, self.hidden_dim)\n",
        "    output = self.map_2_decoder(output)\n",
        "    output_feature = self.map_2_decoder(output_feature)\n",
        "    hidden_states = encoder_outputs[1]\n",
        "    second_2_last_hidden = hidden_states[-2]\n",
        "    pooled_hidden = second_2_last_hidden.mean(1)\n",
        "    pooled_cell = torch.zeros(1, pooled_hidden.shape[0], pooled_hidden.shape[1]).to(device)\n",
        "    pooled_hidden = self.map_2_decoder(pooled_hidden)\n",
        "    pooled_cell = self.map_2_decoder(pooled_cell)\n",
        "    hidden = (pooled_hidden.view(1, pooled_hidden.shape[0], pooled_hidden.shape[1]), pooled_cell)\n",
        "\n",
        "    return hidden, output, output_feature\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGofqPk3-xlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Attention class to be used in the decoder to calculate attention distribution.\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_dim):\n",
        "      super(Attention, self).__init__()\n",
        "      # attention\n",
        "      self.hidden_dim = hidden_dim\n",
        "      self.W_c = nn.Linear(1, self.hidden_dim, bias=False)\n",
        "      self.decode_proj = nn.Linear(self.hidden_dim*2, self.hidden_dim)\n",
        "      self.v = nn.Linear(self.hidden_dim, 1, bias=False)\n",
        "\n",
        "\n",
        "  def forward(self, s_t_hat, encoder_outputs, encoder_feature, coverage):\n",
        "      b, t_k, n = list(encoder_outputs.size())\n",
        "\n",
        "      attention_mask = ~(encoder_outputs[:,:,0] == 0).to(device)\n",
        "\n",
        "      dec_feat = self.decode_proj(s_t_hat) \n",
        "      dec_feat = dec_feat.unsqueeze(1)\n",
        "      dec_feat_expanded = dec_feat.expand(b, t_k, n).contiguous() \n",
        "      dec_feat_expanded = dec_feat_expanded.view(-1, n)  \n",
        "\n",
        "      att_features = encoder_feature.unsqueeze(0) + dec_feat_expanded\n",
        " \n",
        "      coverage_input = coverage.view(-1, 1)  \n",
        "      coverage_feature = self.W_c(coverage_input) \n",
        "      att_features = att_features + coverage_feature\n",
        "\n",
        "      e = torch.tanh(att_features) \n",
        "      scores = self.v(e) \n",
        "      scores = scores.view(-1, t_k)\n",
        "\n",
        "      attn_dist_ = F.softmax(scores, dim=1)*attention_mask\n",
        "      normalization_factor = attn_dist_.sum(1, keepdim=True)\n",
        "      attn_dist = attn_dist_ / normalization_factor\n",
        "\n",
        "      attn_dist = attn_dist.unsqueeze(1)  \n",
        "      c_t = torch.bmm(attn_dist, encoder_outputs)  \n",
        "      c_t = c_t.view(-1, self.hidden_dim)  \n",
        "\n",
        "      attn_dist = attn_dist.view(-1, t_k)  \n",
        "      coverage = coverage.view(-1, t_k)\n",
        "      coverage = coverage + attn_dist\n",
        "    \n",
        "      return c_t, attn_dist, coverage\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLvhigJPwz5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decoder class to decode the hidden states and incorporate the attention \n",
        "# mechanism and calculate words of the output sequence.\n",
        "class Decoder(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_dim, embed_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed_dim = embed_dim\n",
        "    self.output_dim = output_dim\n",
        "    \n",
        "    self.embed_layer = nn.Embedding(self.input_dim, self.embed_dim)\n",
        "    self.prep_encoder = nn.Linear(768, self.hidden_dim)\n",
        "    self.rnn = nn.LSTM(self.embed_dim, self.hidden_dim, batch_first=True)\n",
        "    self.drop = nn.Dropout(p=.1)\n",
        "    self.attention = Attention(self.hidden_dim)\n",
        "    self.x_context = nn.Linear(self.hidden_dim*2 + self.embed_dim, self.embed_dim)\n",
        "    self.point_gen = nn.Linear(self.hidden_dim*3 + self.embed_dim, 1)\n",
        "    self.out = nn.Linear(self.hidden_dim*2, self.hidden_dim)\n",
        "    self.final_out = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "  \n",
        "  \n",
        "  def forward(self, target_forced, hidden, encoder_output, encoder_feature, coverage, context_t_1, extended_vocab, extra_zeros, batch_size):\n",
        "\n",
        "    target_embed = self.embed_layer(target_forced)\n",
        "    x = self.x_context(torch.cat((context_t_1, target_embed), 1))\n",
        "    output_rnn, (hidden_output, cell_output) = self.rnn(x.unsqueeze(1), hidden)\n",
        "\n",
        "    output_rnn = self.drop(output_rnn)\n",
        "    hidden_output = self.drop(hidden_output)\n",
        "    cell_output = self.drop(cell_output)\n",
        "\n",
        "    rnn_wts = torch.cat((hidden_output.view(-1, self.hidden_dim), \n",
        "                           cell_output.view(-1, self.hidden_dim)), 1)\n",
        "    \n",
        "\n",
        "    c_t, attn_dist, coverage_updated = self.attention(rnn_wts, encoder_output, encoder_feature, coverage)\n",
        "    coverage = coverage_updated\n",
        "\n",
        "    point_gen_input = torch.cat((c_t, rnn_wts, x), 1)\n",
        "    point_gen = self.point_gen(point_gen_input)\n",
        "    point_gen = torch.sigmoid(point_gen)\n",
        "\n",
        "    output = torch.cat((output_rnn.view(-1, self.hidden_dim), c_t), 1)\n",
        "    output = self.out(output)\n",
        "    output = self.final_out(output)\n",
        "\n",
        "    vocab_dist = F.softmax(output, dim=1)\n",
        "    point_gen_vocab_dist = point_gen * vocab_dist\n",
        "    point_gen_att_dist = (1 - point_gen) * attn_dist\n",
        "    \n",
        "\n",
        "\n",
        "    if extra_zeros is not None:\n",
        "      point_gen_vocab_dist = torch.cat([point_gen_vocab_dist, extra_zeros], 1)\n",
        "\n",
        "\n",
        "\n",
        "    if extended_vocab.shape != attn_dist.shape:\n",
        "      print(\"extended_vocab\", extended_vocab.shape)\n",
        "      print(\"attn_dist\", attn_dist.shape)\n",
        "  \n",
        "    final_dist = point_gen_vocab_dist.scatter_add(1, extended_vocab, attn_dist)\n",
        "\n",
        "    \n",
        "    return final_dist, hidden_output, cell_output, attn_dist, coverage "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07GWJudqpjfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PointerGen class to create the final pytorch module which\n",
        "# contains all the previous components.\n",
        "class PointerGen(nn.Module):\n",
        "    def __init__(self, encoder, decoder, is_eval=False):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        if is_eval:\n",
        "          self.encoder = encoder.eval()\n",
        "          self.decoder = decoder.eval()       \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kVAu60CbE5Y",
        "colab_type": "text"
      },
      "source": [
        "# Train Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-98DmfWI8uVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad batches of data for the model.\n",
        "def pad_data(data, pad_id, width=-1):\n",
        "  if (width == -1):\n",
        "      width = max(len(d) for d in data)\n",
        "  rtn_data = [d + [pad_id] * (width - len(d)) for d in data]\n",
        "  return rtn_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5SXUEapB4ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad wordpiece tags for the model.\n",
        "def pad_tags(data, pad_id, width=-1):\n",
        "  if (width == -1):\n",
        "      width = max(len(d) for d in data)\n",
        "  rtn_data = [d + [pad_id] * (width - len(d)) for d in data]\n",
        "  return rtn_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c2OMHET_nhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model weights to a local file. \n",
        "def save_model(model, optimizer):\n",
        "  state = {\n",
        "      'encoder_state_dict': model.encoder.state_dict(),\n",
        "      'decoder_state_dict': model.decoder.state_dict(),\n",
        "      'optimizer': optimizer.state_dict()\n",
        "  }\n",
        "  model_save_path = os.path.join(\"/content/drive/My Drive/DS 4420/Project/models/\", 'model')\n",
        "  torch.save(state, model_save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKw0ohGZyVcx",
        "colab_type": "text"
      },
      "source": [
        "# Train Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR1p22slPoDV",
        "colab_type": "text"
      },
      "source": [
        "Code from this section was influenced from a pytorch implementation of the PointerGen Model at this Github Page https://github.com/atulkum/pointer_summarizer and the code from the Attention Is All You Need paper at this Github Page https://github.com/becxer/pointer-generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aezVAljqpXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "# Train method to train model and save losses and model locally.\n",
        "def train(model, train_data, validation_data, batch_size, optimizer, num_epochs):\n",
        "  running_avg_loss = 0.0\n",
        "  running_avg_valid_loss = 0.0\n",
        "  model.train()\n",
        "  start = time.time()\n",
        "  batch_size = batch_size\n",
        "  \n",
        "  train_losses = []\n",
        "  validation_losses = []\n",
        "  for epoch in tqdm(range(num_epochs)):\n",
        "    epoch_loss = 0.0\n",
        "    epoch_loss_validation = 0.0\n",
        "    random.shuffle(train_data)\n",
        "    random.shuffle(validation_data)\n",
        "    count = 0\n",
        "    for i in range(0, len(train_data), batch_size):\n",
        "      count +=1\n",
        "      data_subset = train_data[i:i+batch_size]\n",
        "      loss = train_batch(model, optimizer, data_subset, True)\n",
        "      #print(\"train loss: \", loss)\n",
        "      epoch_loss += loss\n",
        "\n",
        "      if math.isnan(loss):\n",
        "        print(count)\n",
        "        print(\"loss: \", loss)\n",
        "      if math.isnan(epoch_loss):\n",
        "        print(count)\n",
        "        print(epoch_loss)\n",
        "\n",
        "\n",
        "    # Evaluate model on validation set\n",
        "    for j in range(0, len(validation_data), batch_size):\n",
        "        batch = validation_data[j:j+batch_size]\n",
        "\n",
        "        with torch.no_grad(): \n",
        "          loss_validation = train_batch(model, optimizer, batch, False) \n",
        "          epoch_loss_validation += loss_validation\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    validation_losses.append(epoch_loss_validation)\n",
        "    tqdm.write(f\"Train Loss (Epoch {epoch}) : {epoch_loss}\")\n",
        "    tqdm.write(f\"Validation Loss (Epoch {epoch}) : {epoch_loss_validation}\")\n",
        "\n",
        "\n",
        "    f_train = open(\"/content/drive/My Drive/DS 4420/Project/loss/losses_train.txt\", \"a\")\n",
        "    f_validation = open(\"/content/drive/My Drive/DS 4420/Project/loss/losses_validation.txt\", \"a\")\n",
        "    f_train.write(str(epoch) + \", \" + str(epoch_loss) + \"\\n\")\n",
        "    f_validation.write(str(epoch) + \", \" + str(epoch_loss_validation) + \"\\n\")\n",
        "\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      print(\"model saved\")\n",
        "      torch.save({\n",
        "            'epoch': epoch,\n",
        "            'loss': epoch_loss,\n",
        "            'model_state_dict': p_gen_model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, \"/content/drive/My Drive/DS 4420/Project/models/model_trained\")\n",
        "      \n",
        "    if epoch == 99:\n",
        "      print(\"model saved\")\n",
        "      torch.save({\n",
        "            'epoch': epoch,\n",
        "            'loss': epoch_loss,\n",
        "            'train_losses': train_losses,\n",
        "            'validation_losses': validation_losses,\n",
        "            'model_state_dict': p_gen_model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, \"/content/drive/My Drive/DS 4420/Project/models/model_trained\")\n",
        "    \n",
        "  return train_losses, validation_losses\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyTg9Se-7oHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "\n",
        "# Train one batch of data and calculate loss.\n",
        "def train_batch(model, optimizer, batch, training):\n",
        "  prep_reviews = [x['src'].tolist()[0] for x in batch]\n",
        "  prep_targets = [x['tgt'].tolist()[0] for x in batch]\n",
        "  prep_tags = [x['ref_tags'] for x in batch]\n",
        "  prep_reviews_oov = [x['src_oov_idx'] for x in batch]\n",
        "  prep_targets_oov = [x['tgt_oov_idx'].tolist()[0] for x in batch]\n",
        "  dec_lens = [len(x['tgt'].tolist()[0]) for x in batch]\n",
        "  dec_lens = torch.tensor(dec_lens).to(device)\n",
        "\n",
        "\n",
        "  batch_reviews = torch.tensor(pad_data(prep_reviews, 0)).to(device)\n",
        "  batch_targets = torch.tensor(pad_data(prep_targets, 0)).to(device)\n",
        "  batch_extended_reviews = torch.tensor(pad_data(prep_reviews_oov, 0)).to(device)\n",
        "  batch_extended_targets = torch.tensor(pad_data(prep_targets_oov, 0)).to(device)\n",
        "  padded_prep_tags = pad_tags(prep_tags, False)\n",
        "\n",
        "\n",
        "  batch_attn_mask = ~(batch_reviews == 0).to(device)\n",
        "  batch_attn_mask_dec = ~(batch_targets == 0).to(device)\n",
        "  batch_max_oovs = max([len(x['srv_oovs']) for x in batch])\n",
        "\n",
        "  extra_zeros = None\n",
        "  if batch_max_oovs > 0:\n",
        "    extra_zeros = Variable(torch.zeros((batch_size, batch_max_oovs)))\n",
        "\n",
        "\n",
        "  context_t_1 = Variable(torch.zeros(len(batch), 2*model.decoder.hidden_dim)).to(device)\n",
        "  max_len = batch_targets.shape[1]\n",
        "  vocab_size = model.decoder.output_dim\n",
        "\n",
        "  step_losses = []\n",
        "  \n",
        "  if training:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  hidden, encoder_output, encoder_feature = model.encoder(batch_reviews, batch_attn_mask, padded_prep_tags)\n",
        "  coverage = Variable(torch.zeros(encoder_output.shape[0], encoder_output.shape[1])).to(device)\n",
        "\n",
        "  for t in range(0, max_len):\n",
        "      target_forced = batch_targets[:, t]\n",
        "      final_dist, hidden_output, cell_output, point_gen_att_dist, next_coverage = \\\n",
        "      model.decoder(target_forced, hidden, encoder_output, encoder_feature, \n",
        "                    coverage, context_t_1, batch_extended_reviews, extra_zeros, len(batch))   \n",
        "\n",
        "      target = batch_extended_targets[:, t]\n",
        "      gold_probs = torch.gather(final_dist, 1, target.unsqueeze(1)).squeeze()\n",
        "      step_loss = -torch.log(gold_probs + 1e-12)\n",
        "\n",
        "      step_coverage_loss = torch.sum(torch.min(point_gen_att_dist, coverage), 1)\n",
        "      step_loss = step_loss + step_coverage_loss\n",
        "      # Update coverage\n",
        "      coverage = next_coverage\n",
        "\n",
        "      step_mask = batch_attn_mask_dec[:, t]\n",
        "      step_loss = step_loss * step_mask\n",
        "      step_losses.append(step_loss)\n",
        "  \n",
        "  sum_losses = torch.sum(torch.stack(step_losses, 1), 1)\n",
        "  batch_avg_loss = sum_losses / dec_lens\n",
        "  loss = torch.mean(batch_avg_loss)\n",
        "\n",
        "  \n",
        "\n",
        "  if math.isnan(loss):\n",
        "    print(\"sum losses: \", sum_losses)\n",
        "    print(\"seq lens: \", dec_lens)\n",
        "    print(\"batch avg loss: \", batch_avg_loss)\n",
        "    print(\"loss\", loss)\n",
        "    pdb.set_trace()\n",
        "    print(\"loss before back: \", loss)\n",
        "  \n",
        "  if training:\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-Wq3n_ZUNAN",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YvGQEEMxYbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embed_dim = 512\n",
        "# hidden_dim_encoder = 768\n",
        "# hidden_dim_decoder = 256\n",
        "# vocab_size = 30522\n",
        "# decoder_vocab_size= len(word_to_ix) \n",
        "\n",
        "# encoder = Encoder(vocab_size, embed_dim, hidden_dim_encoder, hidden_dim_decoder)\n",
        "# decoder = Decoder(decoder_vocab_size, embed_dim, hidden_dim_decoder, decoder_vocab_size)\n",
        "\n",
        "# p_gen_model = PointerGen(encoder, decoder).to(device)\n",
        "# optimizer = optim.Adagrad(p_gen_model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "511bVTJKPyoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set model parameters.\n",
        "embed_dim = 512\n",
        "hidden_dim_encoder = 768\n",
        "hidden_dim_decoder = 256\n",
        "vocab_size = 30522\n",
        "decoder_vocab_size= len(word_to_ix) \n",
        "\n",
        "# Initialize model parameters.\n",
        "e = Encoder(vocab_size, embed_dim, hidden_dim_encoder, hidden_dim_decoder)\n",
        "d = Decoder(decoder_vocab_size, embed_dim, hidden_dim_decoder, decoder_vocab_size)\n",
        "\n",
        "# Initialize model and optimizer.\n",
        "p_gen_model = PointerGen(e, d).to(device)\n",
        "optimizer = optim.Adagrad(p_gen_model.parameters(), lr=0.01)\n",
        "\n",
        "# Load in model and optimizer weights.\n",
        "checkpoint = torch.load(\"/content/drive/My Drive/DS 4420/Project/models/model_trained\")\n",
        "p_gen_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKKZT38t7Zyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get number of parameters in the model.\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5vphvIH7lG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96f193c0-7e86-46d1-a490-8750ce3bb1cc"
      },
      "source": [
        "# Number of parameters in the model.\n",
        "get_n_params(p_gen_model)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83222177"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROvgcoY_SbrS",
        "colab_type": "code",
        "outputId": "8a7e38b9-a5d5-4655-97d5-0ce262718225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a7a66050bed4f609e84c28e5568c905",
            "2a3b899aa8ee4f4f87005d5ec4d2306c",
            "8f68ea15445e4d84842336bc9bdc01d0",
            "5de97783bb2a41a8b22c90bf73fea799",
            "c4a6574f1b7f445d9433783221573079",
            "0f1ee68cf47b40caa4797f165ad6f4af",
            "72baa954c6704765b23f99bf997b1873",
            "dd00b3b9d3b945dd974978137b0f982f"
          ]
        }
      },
      "source": [
        "# Train the model.\n",
        "train_losses, validation_losses = train(p_gen_model, tokenized_reviews_train, tokenized_reviews_validation, 8, optimizer, 100)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a7a66050bed4f609e84c28e5568c905",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rTrain Loss (Epoch 0) : 696.4081320762634\n",
            "\rValidation Loss (Epoch 0) : 521.5600228309631\n",
            "model saved\n",
            "Train Loss (Epoch 1) : 694.6245937645435\n",
            "Validation Loss (Epoch 1) : 517.8089389801025\n",
            "Train Loss (Epoch 2) : 696.3484179973602\n",
            "Validation Loss (Epoch 2) : 524.2287536859512\n",
            "Train Loss (Epoch 3) : 698.9994866251945\n",
            "Validation Loss (Epoch 3) : 521.6674904823303\n",
            "Train Loss (Epoch 4) : 696.3905528187752\n",
            "Validation Loss (Epoch 4) : 520.9916157722473\n",
            "Train Loss (Epoch 5) : 690.0340883135796\n",
            "Validation Loss (Epoch 5) : 522.2678681612015\n",
            "Train Loss (Epoch 6) : 690.5128029286861\n",
            "Validation Loss (Epoch 6) : 522.8696937561035\n",
            "Train Loss (Epoch 7) : 695.4704436659813\n",
            "Validation Loss (Epoch 7) : 524.4152100086212\n",
            "Train Loss (Epoch 8) : 694.116880595684\n",
            "Validation Loss (Epoch 8) : 523.7129027843475\n",
            "Train Loss (Epoch 9) : 697.5944540202618\n",
            "Validation Loss (Epoch 9) : 521.6955256462097\n",
            "Train Loss (Epoch 10) : 690.3024416267872\n",
            "Validation Loss (Epoch 10) : 520.1099997758865\n",
            "model saved\n",
            "Train Loss (Epoch 11) : 693.2498598396778\n",
            "Validation Loss (Epoch 11) : 522.2970819473267\n",
            "Train Loss (Epoch 12) : 691.4413813650608\n",
            "Validation Loss (Epoch 12) : 524.7755720615387\n",
            "Train Loss (Epoch 13) : 691.663292735815\n",
            "Validation Loss (Epoch 13) : 523.0432999134064\n",
            "Train Loss (Epoch 14) : 683.8171079754829\n",
            "Validation Loss (Epoch 14) : 523.476704120636\n",
            "Train Loss (Epoch 15) : 691.2493477165699\n",
            "Validation Loss (Epoch 15) : 523.666130065918\n",
            "Train Loss (Epoch 16) : 690.4338262081146\n",
            "Validation Loss (Epoch 16) : 520.6345211267471\n",
            "Train Loss (Epoch 17) : 690.3703638613224\n",
            "Validation Loss (Epoch 17) : 522.7730703353882\n",
            "Train Loss (Epoch 18) : 693.5939330458641\n",
            "Validation Loss (Epoch 18) : 521.6264632940292\n",
            "Train Loss (Epoch 19) : 693.5643202364445\n",
            "Validation Loss (Epoch 19) : 524.4656975269318\n",
            "Train Loss (Epoch 20) : 691.5711804628372\n",
            "Validation Loss (Epoch 20) : 523.808762550354\n",
            "model saved\n",
            "Train Loss (Epoch 21) : 694.8519485890865\n",
            "Validation Loss (Epoch 21) : 523.9548888206482\n",
            "Train Loss (Epoch 22) : 689.3264413774014\n",
            "Validation Loss (Epoch 22) : 520.6639475822449\n",
            "Train Loss (Epoch 23) : 689.0501411557198\n",
            "Validation Loss (Epoch 23) : 521.9989206790924\n",
            "Train Loss (Epoch 24) : 689.2558058202267\n",
            "Validation Loss (Epoch 24) : 524.8588259220123\n",
            "Train Loss (Epoch 25) : 688.9977838993073\n",
            "Validation Loss (Epoch 25) : 520.8496267795563\n",
            "Train Loss (Epoch 26) : 692.7537997961044\n",
            "Validation Loss (Epoch 26) : 524.0421800613403\n",
            "Train Loss (Epoch 27) : 688.3723600804806\n",
            "Validation Loss (Epoch 27) : 523.1566323041916\n",
            "Train Loss (Epoch 28) : 689.8470994830132\n",
            "Validation Loss (Epoch 28) : 523.7026380300522\n",
            "Train Loss (Epoch 29) : 688.9269131720066\n",
            "Validation Loss (Epoch 29) : 524.5530714988708\n",
            "Train Loss (Epoch 30) : 685.3582349419594\n",
            "Validation Loss (Epoch 30) : 523.1530268192291\n",
            "model saved\n",
            "Train Loss (Epoch 31) : 689.3842085003853\n",
            "Validation Loss (Epoch 31) : 522.8341927528381\n",
            "Train Loss (Epoch 32) : 687.8953768908978\n",
            "Validation Loss (Epoch 32) : 520.6374638080597\n",
            "Train Loss (Epoch 33) : 690.3732602000237\n",
            "Validation Loss (Epoch 33) : 523.1366206407547\n",
            "Train Loss (Epoch 34) : 689.3808872997761\n",
            "Validation Loss (Epoch 34) : 525.2512774467468\n",
            "Train Loss (Epoch 35) : 687.7936477065086\n",
            "Validation Loss (Epoch 35) : 522.2426731586456\n",
            "Train Loss (Epoch 36) : 687.526428759098\n",
            "Validation Loss (Epoch 36) : 526.0292924642563\n",
            "Train Loss (Epoch 37) : 686.0314121246338\n",
            "Validation Loss (Epoch 37) : 521.4988169670105\n",
            "Train Loss (Epoch 38) : 687.9794031381607\n",
            "Validation Loss (Epoch 38) : 523.4756395816803\n",
            "Train Loss (Epoch 39) : 686.7994624376297\n",
            "Validation Loss (Epoch 39) : 522.437605381012\n",
            "Train Loss (Epoch 40) : 686.5709770619869\n",
            "Validation Loss (Epoch 40) : 522.6043626070023\n",
            "model saved\n",
            "Train Loss (Epoch 41) : 686.4702263474464\n",
            "Validation Loss (Epoch 41) : 524.3382222652435\n",
            "Train Loss (Epoch 42) : 688.5912188887596\n",
            "Validation Loss (Epoch 42) : 526.6642355918884\n",
            "Train Loss (Epoch 43) : 688.6027490794659\n",
            "Validation Loss (Epoch 43) : 524.0875771045685\n",
            "Train Loss (Epoch 44) : 686.814285993576\n",
            "Validation Loss (Epoch 44) : 522.9568101167679\n",
            "Train Loss (Epoch 45) : 688.6503418982029\n",
            "Validation Loss (Epoch 45) : 526.0801303386688\n",
            "Train Loss (Epoch 46) : 687.0034000277519\n",
            "Validation Loss (Epoch 46) : 523.1596779823303\n",
            "Train Loss (Epoch 47) : 688.9143428504467\n",
            "Validation Loss (Epoch 47) : 523.0408906936646\n",
            "Train Loss (Epoch 48) : 686.7115897238255\n",
            "Validation Loss (Epoch 48) : 522.0681416988373\n",
            "Train Loss (Epoch 49) : 684.212645471096\n",
            "Validation Loss (Epoch 49) : 523.406815290451\n",
            "Train Loss (Epoch 50) : 685.3882456421852\n",
            "Validation Loss (Epoch 50) : 522.6738120317459\n",
            "model saved\n",
            "Train Loss (Epoch 51) : 684.6529666483402\n",
            "Validation Loss (Epoch 51) : 523.9093141555786\n",
            "Train Loss (Epoch 52) : 686.587381362915\n",
            "Validation Loss (Epoch 52) : 522.3980507850647\n",
            "Train Loss (Epoch 53) : 688.7059526741505\n",
            "Validation Loss (Epoch 53) : 527.3478565216064\n",
            "Train Loss (Epoch 54) : 684.138280570507\n",
            "Validation Loss (Epoch 54) : 525.2640407085419\n",
            "Train Loss (Epoch 55) : 685.646154820919\n",
            "Validation Loss (Epoch 55) : 524.7280571460724\n",
            "Train Loss (Epoch 56) : 693.9929681420326\n",
            "Validation Loss (Epoch 56) : 522.5204994678497\n",
            "Train Loss (Epoch 57) : 685.9700509309769\n",
            "Validation Loss (Epoch 57) : 521.6432018280029\n",
            "Train Loss (Epoch 58) : 685.508098512888\n",
            "Validation Loss (Epoch 58) : 523.4896173477173\n",
            "Train Loss (Epoch 59) : 685.016892015934\n",
            "Validation Loss (Epoch 59) : 521.843874335289\n",
            "Train Loss (Epoch 60) : 683.297082722187\n",
            "Validation Loss (Epoch 60) : 523.6906733512878\n",
            "model saved\n",
            "Train Loss (Epoch 61) : 684.247035741806\n",
            "Validation Loss (Epoch 61) : 524.0109150409698\n",
            "Train Loss (Epoch 62) : 686.0279124081135\n",
            "Validation Loss (Epoch 62) : 522.7064408063889\n",
            "Train Loss (Epoch 63) : 680.1448156237602\n",
            "Validation Loss (Epoch 63) : 524.3492434024811\n",
            "Train Loss (Epoch 64) : 685.1007214784622\n",
            "Validation Loss (Epoch 64) : 522.197093963623\n",
            "Train Loss (Epoch 65) : 683.3878509402275\n",
            "Validation Loss (Epoch 65) : 522.268990278244\n",
            "Train Loss (Epoch 66) : 681.5303902328014\n",
            "Validation Loss (Epoch 66) : 525.4262046813965\n",
            "Train Loss (Epoch 67) : 682.5399051308632\n",
            "Validation Loss (Epoch 67) : 523.5192770957947\n",
            "Train Loss (Epoch 68) : 683.0108437240124\n",
            "Validation Loss (Epoch 68) : 526.1558685302734\n",
            "Train Loss (Epoch 69) : 683.2721445560455\n",
            "Validation Loss (Epoch 69) : 525.178288936615\n",
            "Train Loss (Epoch 70) : 680.1797914505005\n",
            "Validation Loss (Epoch 70) : 523.44690990448\n",
            "model saved\n",
            "Train Loss (Epoch 71) : 684.0399833321571\n",
            "Validation Loss (Epoch 71) : 525.5707161426544\n",
            "Train Loss (Epoch 72) : 682.8826714754105\n",
            "Validation Loss (Epoch 72) : 523.9378935098648\n",
            "Train Loss (Epoch 73) : 678.3394271433353\n",
            "Validation Loss (Epoch 73) : 525.5879368782043\n",
            "Train Loss (Epoch 74) : 683.0019824504852\n",
            "Validation Loss (Epoch 74) : 525.8381077051163\n",
            "Train Loss (Epoch 75) : 679.7817229032516\n",
            "Validation Loss (Epoch 75) : 523.2360465526581\n",
            "Train Loss (Epoch 76) : 682.4558139145374\n",
            "Validation Loss (Epoch 76) : 525.0425306558609\n",
            "Train Loss (Epoch 77) : 682.265235632658\n",
            "Validation Loss (Epoch 77) : 526.253524184227\n",
            "Train Loss (Epoch 78) : 680.2468185126781\n",
            "Validation Loss (Epoch 78) : 525.2450494766235\n",
            "Train Loss (Epoch 79) : 678.9174084365368\n",
            "Validation Loss (Epoch 79) : 524.3517706394196\n",
            "Train Loss (Epoch 80) : 682.7323548197746\n",
            "Validation Loss (Epoch 80) : 523.3843257427216\n",
            "model saved\n",
            "Train Loss (Epoch 81) : 677.8430217206478\n",
            "Validation Loss (Epoch 81) : 524.8941688537598\n",
            "Train Loss (Epoch 82) : 680.5361600220203\n",
            "Validation Loss (Epoch 82) : 524.0179920196533\n",
            "Train Loss (Epoch 83) : 682.2737502753735\n",
            "Validation Loss (Epoch 83) : 526.707846403122\n",
            "Train Loss (Epoch 84) : 679.4211601614952\n",
            "Validation Loss (Epoch 84) : 525.4229173660278\n",
            "Train Loss (Epoch 85) : 678.404673397541\n",
            "Validation Loss (Epoch 85) : 525.0431106090546\n",
            "Train Loss (Epoch 86) : 681.2195613086224\n",
            "Validation Loss (Epoch 86) : 522.6834365129471\n",
            "Train Loss (Epoch 87) : 677.7345578074455\n",
            "Validation Loss (Epoch 87) : 525.9258387088776\n",
            "Train Loss (Epoch 88) : 679.8203885257244\n",
            "Validation Loss (Epoch 88) : 525.4606378078461\n",
            "Train Loss (Epoch 89) : 680.2965440452099\n",
            "Validation Loss (Epoch 89) : 523.8942190408707\n",
            "Train Loss (Epoch 90) : 678.5366407036781\n",
            "Validation Loss (Epoch 90) : 525.7794831991196\n",
            "model saved\n",
            "Train Loss (Epoch 91) : 674.3675727248192\n",
            "Validation Loss (Epoch 91) : 526.5392348766327\n",
            "Train Loss (Epoch 92) : 680.0075781941414\n",
            "Validation Loss (Epoch 92) : 526.2509770393372\n",
            "Train Loss (Epoch 93) : 671.3812305629253\n",
            "Validation Loss (Epoch 93) : 525.6256370544434\n",
            "Train Loss (Epoch 94) : 679.8746705651283\n",
            "Validation Loss (Epoch 94) : 525.4619545936584\n",
            "Train Loss (Epoch 95) : 677.3595611155033\n",
            "Validation Loss (Epoch 95) : 523.9563317298889\n",
            "Train Loss (Epoch 96) : 676.6200481653214\n",
            "Validation Loss (Epoch 96) : 525.2473058700562\n",
            "Train Loss (Epoch 97) : 680.0785094797611\n",
            "Validation Loss (Epoch 97) : 523.3085304498672\n",
            "Train Loss (Epoch 98) : 676.8279814720154\n",
            "Validation Loss (Epoch 98) : 525.3914794921875\n",
            "Train Loss (Epoch 99) : 679.8461287021637\n",
            "Validation Loss (Epoch 99) : 527.4802650213242\n",
            "model saved\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdxyfGV4iTVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save losses.\n",
        "pickle.dump(train_losses, open(\"/content/drive/My Drive/DS 4420/Project/models/train_losses_1450_epochs.pickle\", \"wb\"))\n",
        "pickle.dump(validation_losses, open(\"/content/drive/My Drive/DS 4420/Project/models/valid_losses_1450_epochs.pickle\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEDhly551vDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot losses.\n",
        "def plot(losses, labels):\n",
        "  for i, loss_type in enumerate(losses):\n",
        "    loss_values = losses[i]\n",
        "    epochs = range(1, len(loss_values)+1)\n",
        "\n",
        "    plt.plot(epochs, loss_values, label=labels[i])\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Losses Over Training')\n",
        "    plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDVTTBmr22wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in loss files.\n",
        "losses_50_train = pickle.load(open( \"/content/drive/My Drive/DS 4420/Project/models/train_losses_first_50_epochs.p\", \"rb\" ))\n",
        "losses_100_train = pickle.load(open( \"/content/drive/My Drive/DS 4420/Project/models/train_losses_first_100_epochs.p\", \"rb\" ))\n",
        "losses_150_train = pickle.load(open( \"/content/drive/My Drive/DS 4420/Project/models/train_losses_first_150_epochs.p\", \"rb\" ))\n",
        "losses_200_train = pickle.load(open( \"/content/drive/My Drive/DS 4420/Project/models/train_losses_first_200_epochs.p\", \"rb\" ))\n",
        "\n",
        "losses_50_validation = pickle.load(open( \"/content/drive/My Drive/DS 4420/Project/models/valid_losses_first_50_epochs.p\", \"rb\" ))\n",
        "losses_100_validation = pickle.load(open( \"/content/drive/My Drive/DS 4420/Project/models/valid_losses_first_100_epochs.p\", \"rb\" ))\n",
        "losses_150_validation = pickle.load(open( \"/content/drive/My Drive/DS 4420/Project/models/valid_losses_first_150_epochs.p\", \"rb\" ))\n",
        "losses_200_validation = pickle.load(open( \"/content/drive/My Drive/DS 4420/Project/models/valid_losses_first_200_epochs.p\", \"rb\" ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oij542XN4KgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine losses.\n",
        "train_losses = losses_50_train + losses_100_train + losses_150_train + losses_200_train\n",
        "valid_losses = losses_50_validation + losses_100_validation + losses_150_validation + losses_200_validation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEPyzuH94fQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in other loss files.\n",
        "train_loss_file = pd.read_csv(\"/content/drive/My Drive/DS 4420/Project/loss/losses_train.txt\", sep=',', lineterminator='\\n', names=[\"epoch\", \"loss\"], header=None)\n",
        "valid_loss_file = pd.read_csv(\"/content/drive/My Drive/DS 4420/Project/loss/losses_validation.txt\", sep=',', lineterminator='\\n', names=[\"epoch\", \"loss\"], header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ephTCr9M5Rli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate final losses.\n",
        "rest_train_loss =  train_loss_file['loss'].to_list()\n",
        "rest_valid_loss =  valid_loss_file['loss'].to_list()\n",
        "\n",
        "train_losses = train_losses + rest_train_loss\n",
        "valid_losses = valid_losses + rest_valid_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20byC0Gh6Cum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = []\n",
        "losses.append(train_losses)\n",
        "losses.append(valid_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6zY9eOai9nx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a0e499f0-64f3-446b-c7af-9a1d8dffd12d"
      },
      "source": [
        "plot(losses, ['training', 'validation'])"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qli7lwG63lo",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR9auGI1RC8A",
        "colab_type": "text"
      },
      "source": [
        "Code from this section was influenced from assignment 4 to help implement the beam search decoding strategy. The code can be found in this notebook https://colab.research.google.com/drive/1V24z4u7yWOs60RNcm9wLDMHBAaAncQN9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vYudF8Xg4oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method to evaluate the test set and generate summaries from review.\n",
        "def evaluate(model, data, optimizer, k):\n",
        "  model.eval()\n",
        "  start = time.time()\n",
        "  batch_size = 1\n",
        "\n",
        "  prep_reviews = [data['src'].tolist()[0]]\n",
        "  prep_targets = [data['tgt'].tolist()[0]]\n",
        "  prep_tags = [data['ref_tags']]\n",
        "  prep_reviews_oov = [data['src_oov_idx']]\n",
        "  prep_targets_oov = [data['tgt_oov_idx'].tolist()[0]]\n",
        "  dec_lens = [len(data['tgt'].tolist()[0])]\n",
        "  dec_lens = torch.tensor(dec_lens).to(device)\n",
        "\n",
        "\n",
        "  batch_reviews = torch.tensor(pad_data(prep_reviews, 0)).to(device)\n",
        "  batch_targets = torch.tensor(pad_data(prep_targets, 0)).to(device)\n",
        "  batch_extended_reviews = torch.tensor(pad_data(prep_reviews_oov, 0)).to(device)\n",
        "  batch_extended_targets = torch.tensor(pad_data(prep_targets_oov, 0)).to(device)\n",
        "  padded_prep_tags = pad_tags(prep_tags, False)\n",
        "\n",
        "\n",
        "  batch_attn_mask = ~(batch_reviews == 0).to(device)\n",
        "  batch_attn_mask_dec = ~(batch_targets == 0).to(device)\n",
        "  batch_max_oovs = len(data['srv_oovs'])\n",
        "\n",
        "  extra_zeros = None\n",
        "  if batch_max_oovs > 0:\n",
        "    extra_zeros = Variable(torch.zeros((batch_size, batch_max_oovs)))\n",
        "\n",
        "\n",
        "  context_t_1 = Variable(torch.zeros(1, 2*model.decoder.hidden_dim)).to(device)\n",
        "  max_len = batch_targets.shape[1]\n",
        "  vocab_size = model.decoder.output_dim\n",
        "\n",
        "  hidden, encoder_output, encoder_feature = model.encoder(batch_reviews, batch_attn_mask, padded_prep_tags)\n",
        "  coverage = Variable(torch.zeros(encoder_output.shape[0], encoder_output.shape[1])).to(device)\n",
        "  \n",
        "  outputs = torch.zeros(batch_size, max_len).long().to(device)\n",
        "  outputs[:, 0] = 1\n",
        "\n",
        "  outputs_tf = torch.zeros(batch_size, max_len).long().to(device)\n",
        "\n",
        "\n",
        "  top_k_sequences = [[1]]\n",
        "  top_k_scores = [0.0]\n",
        "\n",
        "\n",
        "  for t in range(0, max_len):\n",
        "    new_sequences = []\n",
        "    new_scores = []\n",
        "    for i, seq in enumerate(top_k_sequences):\n",
        "      #target_forced = batch_targets[:, t]\n",
        "      target_forced = torch.tensor(seq[t]).unsqueeze(0).to(device)\n",
        "      final_dist, hidden_output, cell_output, point_gen_att_dist, next_coverage = \\\n",
        "      model.decoder(target_forced, hidden, encoder_output, encoder_feature, \n",
        "                  coverage, context_t_1, batch_extended_reviews, extra_zeros, 1)   \n",
        "\n",
        "      word_scores = torch.log(final_dist)\n",
        "      for j, score in enumerate(word_scores[0]):\n",
        "        new_score = top_k_scores[i] + score.item()\n",
        "        new_sequences.append(seq + [j])\n",
        "        new_scores.append(new_score)\n",
        "\n",
        "    top_k_index = np.argsort(new_scores)[-k:]\n",
        "    top_k_sequences = [new_sequences[i] for i in top_k_index]\n",
        "    top_k_scores = [new_scores[i] for i in top_k_index]\n",
        "\n",
        "\n",
        "\n",
        "  output = top_k_sequences[0][1:]\n",
        "\n",
        "  for i, val in enumerate(output):\n",
        "    if val == 2:\n",
        "      return output[1:i+1]\n",
        "      \n",
        "  return output[1:]\n",
        "\n",
        "  # for t in range(0, max_len):\n",
        "  #     target_forced = outputs_tf[:, t]\n",
        "  #     final_dist, hidden_output, cell_output, point_gen_att_dist, next_coverage = \\\n",
        "  #     model.decoder(target_forced, hidden, encoder_output, encoder_feature, \n",
        "  #                 coverage, context_t_1, batch_extended_reviews, extra_zeros, 1)   \n",
        "\n",
        "  #     outputs_tf[:, t] = final_dist.argmax()\n",
        "  \n",
        "  # return outputs_tf\n",
        "\n",
        "          # argmax final_dist \n",
        "          # run through decoder function to get word from token value \n",
        "\n",
        "          \n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T39MOH29uI8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sample decoder outputs. Using a beam size of 5.\n",
        "output_train = evaluate(p_gen_model, tokenized_reviews_train[1000], optimizer, 5)\n",
        "output_test = evaluate(p_gen_model, tokenized_reviews_test[50], optimizer, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaxtEUsKaVlv",
        "colab_type": "code",
        "outputId": "7e74949c-8b3c-48ad-b432-8f4495b556a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train set original summary.\n",
        "' '.join(ix_to_word[x] for x in tokenized_reviews_train[1000]['tgt_oov_idx'].tolist()[0])"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'useful if you don t like your current protection <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_lzVUUyLAme",
        "colab_type": "code",
        "outputId": "459c4a12-3e74-46f1-c2cd-c4cadd4e535e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Train set generated summary.\n",
        "' '.join(ix_to_word[x] for x in output_train)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'concept but norton <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdKbrrAvvfoP",
        "colab_type": "code",
        "outputId": "3a27edde-ad2e-4654-99ee-d0e9b3bf4906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test set original summary.\n",
        "' '.join(ix_to_word[x] for x in tokenized_reviews_test[50]['tgt_oov_idx'].tolist()[0])"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good for small landlord business <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n-cmhSyvu_U",
        "colab_type": "code",
        "outputId": "6848aa09-3638-4bec-a053-af739a8a6258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test set generated summary.\n",
        "' '.join(ix_to_word[x] for x in output_test)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tool <eos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CLQSMNR0wtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method to decode outputs over the whole test set to be used to calculate \n",
        "# rouge scores. Summaries and their respective reviews written to local files.\n",
        "def decode(model, data, optimizer, k):\n",
        "  summaries = []\n",
        "  reviews = []\n",
        "\n",
        "  for d in data:\n",
        "    output = evaluate(model, d, optimizer, k)\n",
        "\n",
        "    summary = ' '.join(ix_to_word[x] for x in output)\n",
        "    review = ' '.join(ix_to_word[x] for x in d['src_oov_idx'])\n",
        "\n",
        "    summaries.append(summary)\n",
        "    reviews.append(review)\n",
        "\n",
        "\n",
        "    f_rev = open(\"/content/drive/My Drive/DS 4420/Project/reviews/review.txt\", \"a\")\n",
        "    f_summ = open(\"/content/drive/My Drive/DS 4420/Project/summaries/summary.txt\", \"a\")\n",
        "\n",
        "    f_rev.write(review + \"\\n\")\n",
        "    f_summ.write(summary + \"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X21CvD53RqOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dae10cf0-5817-49f1-9da2-850da61883f2"
      },
      "source": [
        "count = 0\n",
        "for d in tokenized_reviews_test:\n",
        "    count += 1\n",
        "    summary = ' '.join(ix_to_word[x] for x in d['tgt_oov_idx'].tolist()[0])\n",
        "\n",
        "    f_summ = open(\"/content/drive/My Drive/DS 4420/Project/summaries/summary_reference.txt\", \"a\")\n",
        "\n",
        "    f_summ.write(summary + \"\\n\")\n",
        "\n",
        "print(count)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4FFRYWbFCI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decode summaries.\n",
        "decode(p_gen_model, tokenized_reviews_test[521:], optimizer, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYXslFwfEgqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There is a duplicate of one review and summary set because of an indexing\n",
        "# miscalculation when Colab disconnected and had to restart the decoding process.\n",
        "\n",
        "fname = \"/content/drive/My Drive/DS 4420/Project/summaries/summary_refs.txt\"\n",
        "count = 0\n",
        "with open(fname, 'r') as f:\n",
        "    for line in f:\n",
        "        count += 1\n",
        "print(\"Total number of lines is:\", count)\n",
        "\n",
        "fname = \"/content/drive/My Drive/DS 4420/Project/summaries/summary_tgt.txt\"\n",
        "count = 0\n",
        "with open(fname, 'r') as f:\n",
        "    for line in f:\n",
        "        count += 1\n",
        "print(\"Total number of lines is:\", count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYGvYzalyN74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate rouge scores for test set.\n",
        "files_rouge = FilesRouge()\n",
        "scores_final = files_rouge.get_scores(\"/content/drive/My Drive/DS 4420/Project/reviews/review.txt\", \n",
        "                                \"/content/drive/My Drive/DS 4420/Project/summaries/summary.txt\", avg=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75D3WBQqz9dN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "04b4a67f-e380-47c7-a091-e57becf9e334"
      },
      "source": [
        "# Final rouge scores for the test set. \n",
        "scores_final"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge-1': {'f': 0.06218302914764072,\n",
              "  'p': 0.03950183733473425,\n",
              "  'r': 0.4290850197750887},\n",
              " 'rouge-2': {'f': 0.021883574474043696,\n",
              "  'p': 0.013831811055136442,\n",
              "  'r': 0.1573727849472011},\n",
              " 'rouge-l': {'f': 0.0727909084868608,\n",
              "  'p': 0.04426562268566457,\n",
              "  'r': 0.4585600171971012}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}